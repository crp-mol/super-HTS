Loaded and shuffled dataset from "datasets/D1.dat" with 9050 mutants. mean=-12.3579 and std=1.1228 before normalization
Loaded 559 AA properties from "AAIndex.csv"
Found 4 mutable positions: ['150', '57', '85', '19']
Loaded pdb_reference='dock/4e3q.pdb', found active_site={56: ('A', 'L'), 57: ('A', 'W'), 116: ('A', 'S'), 117: ('A', 'G'), 118: ('A', 'S'), 121: ('A', 'N'), 150: ('A', 'Y'), 151: ('A', 'H'), 152: ('A', 'G'), 223: ('A', 'E'), 228: ('A', 'A'), 256: ('A', 'D'), 258: ('A', 'V'), 259: ('A', 'I'), 285: ('A', 'K'), 415: ('A', 'R'), 417: ('A', 'L'), 85: ('B', 'F'), 86: ('B', 'F'), 321: ('B', 'F'), 322: ('B', 'T')}.
Created feature array X.shape=(9050, 21, 30) in 0.49 seconds
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 X_in (InputLayer)              [(None, 30)]         0           []                               
                                                                                                  
 A_in (InputLayer)              [(None, None)]       0           []                               
                                                                                                  
 gcs_conv (GCSConv)             (None, 64)           3904        ['X_in[0][0]',                   
                                                                  'A_in[0][0]']                   
                                                                                                  
 min_cut_pool (MinCutPool)      [(10, 64),           650         ['gcs_conv[0][0]',               
                                 (10, 10)]                        'A_in[0][0]']                   
                                                                                                  
 gcs_conv_1 (GCSConv)           (10, 8)              1032        ['min_cut_pool[0][0]',           
                                                                  'min_cut_pool[0][1]']           
                                                                                                  
 min_cut_pool_1 (MinCutPool)    [(5, 8),             45          ['gcs_conv_1[0][0]',             
                                 (5, 5)]                          'min_cut_pool[0][1]']           
                                                                                                  
 global_avg_pool (GlobalAvgPool  (1, 8)              0           ['min_cut_pool_1[0][0]']         
 )                                                                                                
                                                                                                  
 dense (Dense)                  (1, 1)               9           ['global_avg_pool[0][0]']        
                                                                                                  
==================================================================================================
Total params: 5,640
Trainable params: 5,640
Non-trainable params: 0
__________________________________________________________________________________________________
Fitting model for n_epochs=40 with early stop patience: 5
epoch=1, model_loss=0.75, model_acc=0.66, val_loss=0.33, val_acc=0.56, in 49.53 seconds
epoch=2, model_loss=0.53, model_acc=0.52, val_loss=0.29, val_acc=0.50, in 50.97 seconds
epoch=3, model_loss=0.50, model_acc=0.48, val_loss=0.26, val_acc=0.47, in 48.45 seconds
epoch=4, model_loss=0.49, model_acc=0.46, val_loss=0.27, val_acc=0.46, in 49.80 seconds
epoch=5, model_loss=0.48, model_acc=0.45, val_loss=0.24, val_acc=0.44, in 57.57 seconds
epoch=6, model_loss=0.48, model_acc=0.44, val_loss=0.24, val_acc=0.44, in 63.15 seconds
epoch=7, model_loss=0.47, model_acc=0.43, val_loss=0.23, val_acc=0.43, in 123.14 seconds
epoch=8, model_loss=0.46, model_acc=0.43, val_loss=0.26, val_acc=0.42, in 52.59 seconds
epoch=9, model_loss=0.46, model_acc=0.42, val_loss=0.23, val_acc=0.42, in 62.66 seconds
epoch=10, model_loss=0.45, model_acc=0.42, val_loss=0.24, val_acc=0.42, in 62.73 seconds
epoch=11, model_loss=0.42, model_acc=0.41, val_loss=0.25, val_acc=0.41, in 62.98 seconds
epoch=12, model_loss=0.41, model_acc=0.41, val_loss=0.26, val_acc=0.41, in 51.02 seconds
epoch=13, model_loss=0.40, model_acc=0.41, val_loss=0.25, val_acc=0.41, in 52.07 seconds
epoch=14, model_loss=0.40, model_acc=0.41, val_loss=0.23, val_acc=0.41, in 49.26 seconds
Early stopping.
loss.mean()=0.48, acc.mean()=0.45, val_loss.mean()=0.25, val_acc.mean()=0.44
Printed plot "train_history.png" with training history of loss and accuracy across 14 epochs.
Done with step 500
Done with step 1000
Done with step 1500
Done with step 2000
Done with step 2500
Done with step 3000
Done with step 3500
Done with step 4000
Done with step 4500
Done with step 5000
Done with step 5500
Done with step 6000
Done with step 6500
Done with step 7000
Printed plot title='Training dataset' "training_scatter.png" (n=7240) with R-squared: 0.89, slope: 0.962, and intercept: -0.373
Done with step 500
Done with step 1000
Done with step 1500
Printed plot title='Validation dataset' "validation_scatter.png" (n=1810) with R-squared: 0.88, slope: 0.969, and intercept: -0.309
